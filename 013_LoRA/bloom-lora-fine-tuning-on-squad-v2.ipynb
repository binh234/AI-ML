{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_kg_hide-output":true,"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true},"outputs":[],"source":["!pip install --upgrade bitsandbytes datasets accelerate loralib\n","!pip install --upgrade peft transformers"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2023-06-14T14:09:13.190124Z","iopub.status.busy":"2023-06-14T14:09:13.189686Z","iopub.status.idle":"2023-06-14T14:09:13.200774Z","shell.execute_reply":"2023-06-14T14:09:13.199382Z","shell.execute_reply.started":"2023-06-14T14:09:13.190085Z"},"trusted":true},"outputs":[],"source":["import os\n","os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\""]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# Initialization"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-06-14T14:09:13.558195Z","iopub.status.busy":"2023-06-14T14:09:13.557840Z","iopub.status.idle":"2023-06-14T14:09:24.225604Z","shell.execute_reply":"2023-06-14T14:09:24.224566Z","shell.execute_reply.started":"2023-06-14T14:09:13.558165Z"},"trusted":true},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import bitsandbytes as bnb\n","from transformers import AutoTokenizer, AutoConfig, AutoModelForCausalLM\n","\n","model = AutoModelForCausalLM.from_pretrained(\n","    \"bigscience/bloom-560m\", \n","    torch_dtype=torch.float16,\n","    device_map='auto',\n",")\n","\n","tokenizer = AutoTokenizer.from_pretrained(\"bigscience/tokenizer\")"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2023-06-14T14:09:24.228058Z","iopub.status.busy":"2023-06-14T14:09:24.227608Z","iopub.status.idle":"2023-06-14T14:09:24.235768Z","shell.execute_reply":"2023-06-14T14:09:24.234630Z","shell.execute_reply.started":"2023-06-14T14:09:24.228024Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["BloomForCausalLM(\n","  (transformer): BloomModel(\n","    (word_embeddings): Embedding(250880, 1024)\n","    (word_embeddings_layernorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","    (h): ModuleList(\n","      (0-23): 24 x BloomBlock(\n","        (input_layernorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","        (self_attention): BloomAttention(\n","          (query_key_value): Linear(in_features=1024, out_features=3072, bias=True)\n","          (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","          (attention_dropout): Dropout(p=0.0, inplace=False)\n","        )\n","        (post_attention_layernorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","        (mlp): BloomMLP(\n","          (dense_h_to_4h): Linear(in_features=1024, out_features=4096, bias=True)\n","          (gelu_impl): BloomGelu()\n","          (dense_4h_to_h): Linear(in_features=4096, out_features=1024, bias=True)\n","        )\n","      )\n","    )\n","    (ln_f): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","  )\n","  (lm_head): Linear(in_features=1024, out_features=250880, bias=False)\n",")\n"]}],"source":["print(model)"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2023-06-14T14:09:24.237718Z","iopub.status.busy":"2023-06-14T14:09:24.237339Z","iopub.status.idle":"2023-06-14T14:09:24.260043Z","shell.execute_reply":"2023-06-14T14:09:24.258924Z","shell.execute_reply.started":"2023-06-14T14:09:24.237686Z"},"trusted":true},"outputs":[],"source":["for param in model.parameters():\n","    param.requires_grad = False  # freeze the model - train adapters later\n","    if param.ndim == 1:\n","        # cast the small parameters (e.g. layernorm) to fp32 for stability\n","        param.data = param.data.to(torch.float32)\n","\n","model.gradient_checkpointing_enable()  # reduce number of stored activations\n","model.enable_input_require_grads()\n","\n","class CastOutputToFloat(nn.Sequential):\n","    def forward(self, x):\n","        return super().forward(x).to(torch.float32)\n","model.lm_head = CastOutputToFloat(model.lm_head)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# Helper functions"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2023-06-14T14:09:24.263150Z","iopub.status.busy":"2023-06-14T14:09:24.262807Z","iopub.status.idle":"2023-06-14T14:09:24.269231Z","shell.execute_reply":"2023-06-14T14:09:24.268159Z","shell.execute_reply.started":"2023-06-14T14:09:24.263119Z"},"trusted":true},"outputs":[],"source":["def print_trainable_parameters(model):\n","    \"\"\"\n","    Prints the number of trainable parameters in the model.\n","    \"\"\"\n","    trainable_params = 0\n","    all_param = 0\n","    for _, param in model.named_parameters():\n","        all_param += param.numel()\n","        if param.requires_grad:\n","            trainable_params += param.numel()\n","    print(\n","        f\"trainable params: {trainable_params} || all params: {all_param} || trainable%: {100 * trainable_params / all_param}\"\n","    )"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# Build dataset"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2023-06-14T14:09:24.271296Z","iopub.status.busy":"2023-06-14T14:09:24.270655Z","iopub.status.idle":"2023-06-14T14:09:25.423465Z","shell.execute_reply":"2023-06-14T14:09:25.422561Z","shell.execute_reply.started":"2023-06-14T14:09:24.271253Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"c10f235131d04ed48082948d82c1eacf","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/2 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"}],"source":["from datasets import load_dataset\n","\n","qa_dataset = load_dataset(\"squad_v2\")"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2023-06-14T14:09:25.425749Z","iopub.status.busy":"2023-06-14T14:09:25.424733Z","iopub.status.idle":"2023-06-14T14:09:25.890221Z","shell.execute_reply":"2023-06-14T14:09:25.889248Z","shell.execute_reply.started":"2023-06-14T14:09:25.425714Z"},"trusted":true},"outputs":[],"source":["def create_prompt(context, question, answer):\n","    if len(answer[\"text\"]) < 1:\n","        answer = \"Cannot Find Answer\"\n","    else:\n","        answer = answer[\"text\"][0]\n","    prompt_template = f\"### CONTEXT\\n{context}\\n\\n### QUESTION\\n{question}\\n\\n### ANSWER\\n{answer}</s>\"\n","    return prompt_template\n","\n","mapped_qa_dataset = qa_dataset.map(lambda samples: tokenizer(create_prompt(samples['context'], samples['question'], samples['answers'])))"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2023-06-14T14:09:25.892361Z","iopub.status.busy":"2023-06-14T14:09:25.891525Z","iopub.status.idle":"2023-06-14T14:09:25.899741Z","shell.execute_reply":"2023-06-14T14:09:25.898788Z","shell.execute_reply.started":"2023-06-14T14:09:25.892326Z"},"trusted":true},"outputs":[{"data":{"text/plain":["DatasetDict({\n","    train: Dataset({\n","        features: ['id', 'title', 'context', 'question', 'answers', 'input_ids', 'token_type_ids', 'attention_mask'],\n","        num_rows: 130319\n","    })\n","    validation: Dataset({\n","        features: ['id', 'title', 'context', 'question', 'answers', 'input_ids', 'token_type_ids', 'attention_mask'],\n","        num_rows: 11873\n","    })\n","})"]},"execution_count":9,"metadata":{},"output_type":"execute_result"}],"source":["mapped_qa_dataset"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# Setup LoRA"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2023-06-14T14:09:25.902347Z","iopub.status.busy":"2023-06-14T14:09:25.901215Z","iopub.status.idle":"2023-06-14T14:09:26.936298Z","shell.execute_reply":"2023-06-14T14:09:26.935107Z","shell.execute_reply.started":"2023-06-14T14:09:25.902313Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["trainable params: 393216 || all params: 559607808 || trainable%: 0.07026635339584111\n"]}],"source":["from peft import LoraConfig, get_peft_model \n","\n","config = LoraConfig(\n","    r=4,\n","    lora_alpha=8,\n","    target_modules=[\"query_key_value\"],\n","    lora_dropout=0.05,\n","    bias=\"none\",\n","    task_type=\"CAUSAL_LM\"\n",")\n","\n","model = get_peft_model(model, config)\n","print_trainable_parameters(model)"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2023-06-14T14:09:26.937972Z","iopub.status.busy":"2023-06-14T14:09:26.937611Z","iopub.status.idle":"2023-06-14T14:09:26.943443Z","shell.execute_reply":"2023-06-14T14:09:26.942464Z","shell.execute_reply.started":"2023-06-14T14:09:26.937939Z"},"trusted":true},"outputs":[],"source":["# Disable wandb\n","import os\n","os.environ['WANDB_DISABLED'] = 'true'"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2023-06-14T14:09:26.947258Z","iopub.status.busy":"2023-06-14T14:09:26.946910Z","iopub.status.idle":"2023-06-14T14:52:29.104338Z","shell.execute_reply":"2023-06-14T14:52:29.103369Z","shell.execute_reply.started":"2023-06-14T14:09:26.947224Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n","/opt/conda/lib/python3.10/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n","You're using a PreTrainedTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='1000' max='1000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [1000/1000 42:58, Epoch 0/1]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>100</td>\n","      <td>3.041900</td>\n","    </tr>\n","    <tr>\n","      <td>200</td>\n","      <td>2.865800</td>\n","    </tr>\n","    <tr>\n","      <td>300</td>\n","      <td>2.863300</td>\n","    </tr>\n","    <tr>\n","      <td>400</td>\n","      <td>2.847400</td>\n","    </tr>\n","    <tr>\n","      <td>500</td>\n","      <td>2.840200</td>\n","    </tr>\n","    <tr>\n","      <td>600</td>\n","      <td>2.846500</td>\n","    </tr>\n","    <tr>\n","      <td>700</td>\n","      <td>2.812700</td>\n","    </tr>\n","    <tr>\n","      <td>800</td>\n","      <td>2.827600</td>\n","    </tr>\n","    <tr>\n","      <td>900</td>\n","      <td>2.830000</td>\n","    </tr>\n","    <tr>\n","      <td>1000</td>\n","      <td>2.825600</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["TrainOutput(global_step=1000, training_loss=2.8601026000976564, metrics={'train_runtime': 2581.6917, 'train_samples_per_second': 6.197, 'train_steps_per_second': 0.387, 'total_flos': 7538391830790144.0, 'train_loss': 2.8601026000976564, 'epoch': 0.12})"]},"execution_count":12,"metadata":{},"output_type":"execute_result"}],"source":["import transformers\n","\n","trainer = transformers.Trainer(\n","    model=model, \n","    train_dataset=mapped_qa_dataset[\"train\"],\n","    eval_dataset=mapped_qa_dataset[\"validation\"],\n","    args=transformers.TrainingArguments(\n","        per_device_train_batch_size=4, \n","        gradient_accumulation_steps=4,\n","        warmup_steps=100,\n","        learning_rate=1e-3, \n","        fp16=True,\n","        logging_steps=100,\n","        output_dir='outputs',\n","        max_steps=1000,\n","#         num_train_epochs=3,\n","#         evaluation_strategy='epoch',\n","    ),\n","    data_collator=transformers.DataCollatorForLanguageModeling(tokenizer, mlm=False)\n",")\n","model.config.use_cache = False  # silence the warnings. Please re-enable for inference!\n","trainer.train()"]},{"cell_type":"code","execution_count":13,"metadata":{"execution":{"iopub.execute_input":"2023-06-14T14:52:43.584994Z","iopub.status.busy":"2023-06-14T14:52:43.584605Z","iopub.status.idle":"2023-06-14T14:52:43.608499Z","shell.execute_reply":"2023-06-14T14:52:43.607531Z","shell.execute_reply.started":"2023-06-14T14:52:43.584962Z"},"trusted":true},"outputs":[],"source":["model_path = '/kaggle/working/bloom560m_lora_squad'\n","trainer.save_model(model_path)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# Inference"]},{"cell_type":"code","execution_count":14,"metadata":{"execution":{"iopub.execute_input":"2023-06-14T14:52:45.566808Z","iopub.status.busy":"2023-06-14T14:52:45.566438Z","iopub.status.idle":"2023-06-14T14:52:50.185169Z","shell.execute_reply":"2023-06-14T14:52:50.184163Z","shell.execute_reply.started":"2023-06-14T14:52:45.566778Z"},"trusted":true},"outputs":[],"source":["import torch\n","from peft import PeftModel, PeftConfig\n","from transformers import AutoModelForCausalLM, AutoTokenizer\n","\n","config = PeftConfig.from_pretrained(model_path)\n","model = AutoModelForCausalLM.from_pretrained(\n","    config.base_model_name_or_path,\n","    return_dict=True,\n","    load_in_8bit=False,\n","    device_map='auto'\n",")\n","tokenizer = AutoTokenizer.from_pretrained(config.base_model_name_or_path)\n","\n","# Load the Lora model\n","qa_model = PeftModel.from_pretrained(model, model_path)"]},{"cell_type":"code","execution_count":15,"metadata":{"execution":{"iopub.execute_input":"2023-06-14T14:52:53.320941Z","iopub.status.busy":"2023-06-14T14:52:53.320572Z","iopub.status.idle":"2023-06-14T14:52:53.327433Z","shell.execute_reply":"2023-06-14T14:52:53.326448Z","shell.execute_reply.started":"2023-06-14T14:52:53.320911Z"},"trusted":true},"outputs":[],"source":["from IPython.display import display, Markdown\n","\n","def make_inference(context, question, max_new_tokens=200):\n","    batch = tokenizer(f\"### CONTEXT\\n{context}\\n\\n### QUESTION\\n{question}\\n\\n### ANSWER\\n\", return_tensors='pt')\n","\n","    with torch.cuda.amp.autocast():\n","        output_tokens = qa_model.generate(**batch, max_new_tokens=max_new_tokens)\n","\n","    display(Markdown((tokenizer.decode(output_tokens[0], skip_special_tokens=True))))"]},{"cell_type":"code","execution_count":16,"metadata":{"execution":{"iopub.execute_input":"2023-06-14T14:52:54.457932Z","iopub.status.busy":"2023-06-14T14:52:54.456841Z","iopub.status.idle":"2023-06-14T14:52:55.861943Z","shell.execute_reply":"2023-06-14T14:52:55.860722Z","shell.execute_reply.started":"2023-06-14T14:52:54.457893Z"},"trusted":true},"outputs":[{"data":{"text/markdown":["### CONTEXT\n","Cheese is the best food.\n","\n","### QUESTION\n","What is the best food?\n","\n","### ANSWER\n","Cheese"],"text/plain":["<IPython.core.display.Markdown object>"]},"metadata":{},"output_type":"display_data"}],"source":["context = \"Cheese is the best food.\"\n","question = \"What is the best food?\"\n","\n","make_inference(context, question)"]},{"cell_type":"code","execution_count":17,"metadata":{"execution":{"iopub.execute_input":"2023-06-14T14:53:06.457169Z","iopub.status.busy":"2023-06-14T14:53:06.456139Z","iopub.status.idle":"2023-06-14T14:53:07.996277Z","shell.execute_reply":"2023-06-14T14:53:07.995134Z","shell.execute_reply.started":"2023-06-14T14:53:06.457131Z"},"trusted":true},"outputs":[{"data":{"text/markdown":["### CONTEXT\n","Cheese is the best food.\n","\n","### QUESTION\n","How far away is the Moon from the Earth?\n","\n","### ANSWER\n","Cannot Find Answer"],"text/plain":["<IPython.core.display.Markdown object>"]},"metadata":{},"output_type":"display_data"}],"source":["context = \"Cheese is the best food.\"\n","question = \"How far away is the Moon from the Earth?\"\n","\n","make_inference(context, question)"]},{"cell_type":"code","execution_count":18,"metadata":{"execution":{"iopub.execute_input":"2023-06-14T14:53:07.998607Z","iopub.status.busy":"2023-06-14T14:53:07.998156Z","iopub.status.idle":"2023-06-14T14:53:11.718102Z","shell.execute_reply":"2023-06-14T14:53:11.717175Z","shell.execute_reply.started":"2023-06-14T14:53:07.998572Z"},"trusted":true},"outputs":[{"data":{"text/markdown":["### CONTEXT\n","The Moon orbits Earth at an average distance of 384,400 km (238,900 mi), or about 30 times Earth's diameter. Its gravitational influence is the main driver of Earth's tides and very slowly lengthens Earth's day. The Moon's orbit around Earth has a sidereal period of 27.3 days. During each synodic period of 29.5 days, the amount of visible surface illuminated by the Sun varies from none up to 100%, resulting in lunar phases that form the basis for the months of a lunar calendar. The Moon is tidally locked to Earth, which means that the length of a full rotation of the Moon on its own axis causes its same side (the near side) to always face Earth, and the somewhat longer lunar day is the same as the synodic period. However, 59% of the total lunar surface can be seen from Earth through cyclical shifts in perspective known as libration.\n","\n","### QUESTION\n","At what distance does the Moon orbit the Earth?\n","\n","### ANSWER\n","384,400 km"],"text/plain":["<IPython.core.display.Markdown object>"]},"metadata":{},"output_type":"display_data"}],"source":["context = \"The Moon orbits Earth at an average distance of 384,400 km (238,900 mi), or about 30 times Earth's diameter. Its gravitational influence is the main driver of Earth's tides and very slowly lengthens Earth's day. The Moon's orbit around Earth has a sidereal period of 27.3 days. During each synodic period of 29.5 days, the amount of visible surface illuminated by the Sun varies from none up to 100%, resulting in lunar phases that form the basis for the months of a lunar calendar. The Moon is tidally locked to Earth, which means that the length of a full rotation of the Moon on its own axis causes its same side (the near side) to always face Earth, and the somewhat longer lunar day is the same as the synodic period. However, 59% of the total lunar surface can be seen from Earth through cyclical shifts in perspective known as libration.\"\n","question = \"At what distance does the Moon orbit the Earth?\"\n","\n","make_inference(context, question)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.10"}},"nbformat":4,"nbformat_minor":4}
